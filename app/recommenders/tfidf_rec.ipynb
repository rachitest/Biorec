{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "verb_codes = {\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vscode/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "cs_conferences = pd.read_pickle(\"/workspaces/VRA/conference_rec/wikicfp_cs.pkl\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "cs_rec = cs_conferences[[\"Conference Title\", \"WikiCFP Tags\", \"Conference Description\"]]\n",
    "cs_rec.columns = [\"title\", \"tags\", \"description\"]\n",
    "cs_rec = cs_rec.set_index(\"title\")\n",
    "cs_rec[\"soup\"] = cs_rec[\"tags\"] + \" \" + cs_rec[\"description\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def preprocess_sentences(text):\n",
    "    text = text.lower()\n",
    "    temp_sent = []\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    for i, word in enumerate(words):\n",
    "        if tags[i][1] in verb_codes:\n",
    "            lemmatized = lemmatizer.lemmatize(word, 'v')\n",
    "        else:\n",
    "            lemmatized = lemmatizer.lemmatize(word)\n",
    "        if lemmatized not in stop_words and lemmatized.isalpha():\n",
    "            temp_sent.append(lemmatized)\n",
    "            \n",
    "    finalsent = ' '.join(temp_sent)\n",
    "    finalsent = finalsent.replace(\"n't\", \" not\")\n",
    "    finalsent = finalsent.replace(\"'m\", \" am\")\n",
    "    finalsent = finalsent.replace(\"'s\", \" is\")\n",
    "    finalsent = finalsent.replace(\"'re\", \" are\")\n",
    "    finalsent = finalsent.replace(\"'ll\", \" will\")\n",
    "    finalsent = finalsent.replace(\"'ve\", \" have\")\n",
    "    finalsent = finalsent.replace(\"'d\", \" would\")\n",
    "    return finalsent\n",
    "\n",
    "#cs_rec[\"processed_soup\"] = cs_rec[\"soup\"].apply(preprocess_sentences)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tfidfvec = TfidfVectorizer()\n",
    "tfidf_model = tfidfvec.fit_transform(cs_rec[\"processed_soup\"])\n",
    "cos_sim = linear_kernel(tfidf_model, tfidf_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "indices = pd.Series(cs_rec.index)\n",
    "\n",
    "def recommendations(title, cosine_sim = cos_sim):\n",
    "    recommended_conferences = []\n",
    "    index = indices[indices == title].index[0]\n",
    "    similarity_scores = pd.Series(cosine_sim[index]).sort_values(ascending = False)\n",
    "    top_10_conferences = list(similarity_scores.iloc[1:11].index)\n",
    "    for i in top_10_conferences:\n",
    "        recommended_conferences.append(list(cs_rec.index)[i])\n",
    "    return recommended_conferences"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "recommendations(\"CLOUD 2021 : 10th International Conference on Cloud Computing: Services and Architecture\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['IJCCSA 2021 : International Journal on Cloud Computing: Services and Architecture ',\n",
       " 'CLBD 2021 : 2nd International Conference on Cloud and Big Data',\n",
       " 'CBIoT 2021 : 2nd International Conference on Cloud, Big Data and IoT ',\n",
       " 'CLSB  2021 : 2nd International Conference on Cloud Computing, Security and Blockchain ',\n",
       " 'CBW  2021 : 2nd International Conference on Cloud, Big Data and Web Services ',\n",
       " 'IBCOM  2021 : 2nd International Conference on IoT, Blockchain & Cloud Computing',\n",
       " 'CCSEA 2021 : 11th International Conference on Computer Science, Engineering and Applications',\n",
       " 'EMSA  2021 : 10th International Conference on Embedded Systems and Applications ',\n",
       " 'ICCSEA 2021 : 11th International Conference on Computer Science, Engineering and Applications ',\n",
       " 'CSIT 2021 : 8th International Conference on Computer Science and Information Technology ']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "recommendations(\"ECIJ 2021 : Electrical & Computer Engineering: An International Journal\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['EEIEJ 2021 : Emerging Trends in Electrical, Electronics & Instrumentation Engineering: An international Journal',\n",
       " 'ELELIJ 2021 : Electrical and Electronics Engineering: An International Journal ',\n",
       " 'ADEIJ 2021 : Advances in Engineering: an International Journal ',\n",
       " 'CSEIJ 2021 : Computer Science & Engineering: An International Journal',\n",
       " 'IJCSEIT 2021 : International Journal of Computer Science, Engineering and Information Technology',\n",
       " 'MLAIJ 2021 : Machine Learning and Applications: An International Journal ',\n",
       " 'IJSEA 2021 : International Journal of Software Engineering & Applications - ERA 2018 Indexed',\n",
       " 'IJCSEA 2021 : International Journal of Computer Science, Engineering and Applications ',\n",
       " 'IJACEEE 2021 :  International Journal of Applied Control, Electrical and Electronics Engineering ',\n",
       " 'IJCTCM 2021 : International Journal of Control Theory and Computer Modelling ']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "wiki_token = pd.read_pickle(\"/workspaces/vra_conf_rec_app/assets/wikicfp_corpus.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "tfidfvec = TfidfVectorizer()\n",
    "tfidf_model = tfidfvec.fit_transform(wiki_token[\"tokenized_soup\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "query = \"AMIA 2022 Informatics Summit: From discovering innovative methods to learning from exciting real-world applications, AMIA 2022 Informatics Summit attendees will experience the full range of cutting-edge work in translational informatics and clinical data science from inception to implementation. This conference is the ideal setting for researchers, educators, data scientists, software developers and analysts, students, and industry professionals. The size of the conference makes it ideal for developing meaningful new connections and partnerships while learning practical advice to solve real-world challenges. New to the AMIA 2022 Informatics Summit, we have expanded upon the previous Informatics Implementation track to include it as a new theme: Applied Informatics. In addition to selecting one of the three core Programmatic Tracks (Clinical Research Informatics, Data Science, Translational Bioinformatics), authors/presenters can also choose to designate their submission as part of the Applied Informatics theme to highlight the crucial application and implementation focus of their work. This is first time the Informatics Summit convenes outside of San Francisco. We are confident Chicago will bring new collaborations and connections. We look forward to receiving your submissions\"\n",
    "\n",
    "query = preprocess_sentences(query)\n",
    "query = tfidfvec.transform([query])\n",
    "cosine_similarity = cosine_similarity(query, tfidf_model).flatten()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "results = np.argsort(cosine_similarity)[-10:]\n",
    "results = np.flip(results)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "final_recs = wiki_token.loc[wiki_token.index[results]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}